import pandas as pd
import numpy as np
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

print("üî• ADVANCED ANALYSIS: Portland's Hidden Economic Patterns")
print("=" * 90)

df = pd.read_csv("subsets/complete_core_fields.csv", low_memory=False)
print(f"\nAnalyzing {len(df):,} properties\n")

# Prepare data
df['YEAR_BUILT'] = pd.to_numeric(df['YEAR_BUILT'], errors='coerce')
df['MARKET_VALUE'] = pd.to_numeric(df['MARKET_VALUE'], errors='coerce')
df['SQUARE_FEET'] = pd.to_numeric(df['SQUARE_FEET'], errors='coerce')
df['SALE_PRICE'] = pd.to_numeric(df['SALE_PRICE'], errors='coerce')
df['SALE_DATE'] = pd.to_datetime(df['SALE_DATE'], errors='coerce')
df['price_per_sqft'] = df['MARKET_VALUE'] / df['SQUARE_FEET']
df['building_age'] = 2025 - df['YEAR_BUILT']

print("=" * 90)
print("üö® INSIGHT #11: GENTRIFICATION DISPLACEMENT RISK INDEX")
print("=" * 90)

# Calculate gentrification indicators
neighborhood_gent = df.groupby('neighborhood').agg({
    'MARKET_VALUE': ['median', 'std', 'mean'],
    'YEAR_BUILT': 'median',
    'price_per_sqft': ['median', 'std'],
    'PROPERTY_ID': 'count',
    'building_age': 'median'
}).round(2)

neighborhood_gent.columns = ['_'.join(col).strip() for col in neighborhood_gent.columns.values]
neighborhood_gent = neighborhood_gent[neighborhood_gent['PROPERTY_ID_count'] >= 500]

# Gentrification risk factors:
# 1. High price variance (mixed incomes)
# 2. Old housing stock (vulnerable to redevelopment)
# 3. Rising price per sqft (market pressure)
# 4. Lower median values (affordability pressure)

neighborhood_gent['price_variance_score'] = (neighborhood_gent['MARKET_VALUE_std'] / 
                                              neighborhood_gent['MARKET_VALUE_mean'])
neighborhood_gent['age_vulnerability'] = neighborhood_gent['building_age_median'] / 100
neighborhood_gent['affordability_pressure'] = 1 / (neighborhood_gent['MARKET_VALUE_median'] / 1000000)
neighborhood_gent['market_heat'] = neighborhood_gent['price_per_sqft_median'] / 100

# Composite displacement risk score
neighborhood_gent['displacement_risk'] = (
    neighborhood_gent['price_variance_score'].rank(pct=True) * 0.3 +
    neighborhood_gent['age_vulnerability'].rank(pct=True) * 0.2 +
    neighborhood_gent['affordability_pressure'].rank(pct=True) * 0.3 +
    neighborhood_gent['market_heat'].rank(pct=True) * 0.2
) * 100

print("\nüî¥ TOP 20 NEIGHBORHOODS AT HIGHEST DISPLACEMENT RISK:\n")
at_risk = neighborhood_gent.sort_values('displacement_risk', ascending=False).head(20)
for idx, (hood, row) in enumerate(at_risk.iterrows(), 1):
    risk_level = "üî¥üî¥üî¥" if row['displacement_risk'] > 80 else "üî¥üî¥" if row['displacement_risk'] > 70 else "üî¥"
    print(f"{idx:2d}. {hood[:45]:<45} Risk: {row['displacement_risk']:>5.1f} {risk_level}")
    print(f"     Median Value: ${row['MARKET_VALUE_median']:>8,.0f}  |  Avg Age: {row['building_age_median']:.0f}yr  |  Variance: {row['price_variance_score']:.2f}")

print("\n\n" + "=" * 90)
print("üí∏ INSIGHT #12: THE AFFORDABILITY CRISIS - WHO'S BEING PRICED OUT?")
print("=" * 90)

# Analyze affordable housing stock depletion
affordability_tiers = pd.cut(df['MARKET_VALUE'], 
                              bins=[0, 300000, 500000, 750000, 1000000, np.inf],
                              labels=['<300K', '300-500K', '500-750K', '750K-1M', '>1M'])

tier_analysis = df.groupby(affordability_tiers).agg({
    'PROPERTY_ID': 'count',
    'SQUARE_FEET': 'median',
    'building_age': 'median'
})

total_props = len(df)
print("\nHousing Stock by Affordability Tier:\n")
print(f"{'Price Range':<12} {'Count':<12} {'% Stock':<10} {'Median SqFt':<12} {'Avg Age'}")
print("-" * 75)

for tier, row in tier_analysis.iterrows():
    pct = (row['PROPERTY_ID'] / total_props) * 100
    bar = '‚ñà' * int(pct / 2)
    print(f"{str(tier):<12} {int(row['PROPERTY_ID']):>10,}  {pct:>6.1f}%  {bar:<25} {row['SQUARE_FEET']:>6,.0f}  {row['building_age']:>4.0f}yr")

affordable_stock = df[df['MARKET_VALUE'] <= 400000]
print(f"\nüíî Only {len(affordable_stock):,} properties ({len(affordable_stock)/total_props*100:.1f}%) under $400K")
print(f"   Average size: {affordable_stock['SQUARE_FEET'].median():,.0f} sqft")
print(f"   Average age: {affordable_stock['building_age'].median():.0f} years")

print("\n\n" + "=" * 90)
print("üè¶ INSIGHT #13: INSTITUTIONAL LANDLORD TAKEOVER ANALYSIS")
print("=" * 90)

# Identify corporate/institutional ownership patterns
corporate_keywords = ['LLC', 'INC', 'CORP', 'LP', 'COMPANY', 'CO ', 'TRUST', 'PROPERTIES', 
                      'INVESTMENTS', 'CAPITAL', 'FUND', 'HOLDINGS', 'GROUP', 'VENTURES',
                      'PARTNERS', 'MANAGEMENT', 'REAL ESTATE', 'DEVELOPMENT']

df['is_corporate'] = df['OWNER'].str.upper().str.contains('|'.join(corporate_keywords), na=False)

corporate_stats = df.groupby('is_corporate').agg({
    'PROPERTY_ID': 'count',
    'MARKET_VALUE': ['sum', 'median']
})

print("\nOwnership Structure Analysis:\n")
print(f"{'Owner Type':<20} {'Properties':<15} {'% of Total':<12} {'Total Value':<20} {'Median Value'}")
print("-" * 90)

for is_corp, row in corporate_stats.iterrows():
    owner_type = "Corporate/Institutional" if is_corp else "Individual/Family"
    prop_count = row[('PROPERTY_ID', 'count')]
    pct = (prop_count / total_props) * 100
    total_val = row[('MARKET_VALUE', 'sum')]
    median_val = row[('MARKET_VALUE', 'median')]
    print(f"{owner_type:<20} {prop_count:>13,}  {pct:>9.1f}%  ${total_val/1e9:>16.2f}B  ${median_val:>12,.0f}")

# Find neighborhoods with highest corporate ownership
corp_by_hood = df.groupby('neighborhood')['is_corporate'].agg(['sum', 'count'])
corp_by_hood['corp_pct'] = (corp_by_hood['sum'] / corp_by_hood['count'] * 100)
corp_by_hood = corp_by_hood[corp_by_hood['count'] >= 300]

print("\nüè¢ TOP 15 NEIGHBORHOODS WITH HIGHEST CORPORATE OWNERSHIP:\n")
corp_heavy = corp_by_hood.sort_values('corp_pct', ascending=False).head(15)
for idx, (hood, row) in enumerate(corp_heavy.iterrows(), 1):
    print(f"{idx:2d}. {hood[:50]:<50} {row['corp_pct']:>5.1f}% corporate ({int(row['sum']):,} of {int(row['count']):,})")

print("\n\n" + "=" * 90)
print("üìà INSIGHT #14: SALES VELOCITY & MARKET MOMENTUM")
print("=" * 90)

# Analyze recent sales trends
recent_sales = df[df['SALE_DATE'].notna()].copy()
recent_sales['sale_year'] = recent_sales['SALE_DATE'].dt.year
recent_sales['sale_recency'] = 2025 - recent_sales['sale_year']

# Calculate turnover rates by neighborhood
neighborhood_turnover = recent_sales.groupby('neighborhood').agg({
    'sale_year': lambda x: (x >= 2020).sum(),  # Sales in last 5 years
    'PROPERTY_ID': 'count'
}).rename(columns={'sale_year': 'recent_sales', 'PROPERTY_ID': 'total_with_sales'})

total_by_hood = df.groupby('neighborhood')['PROPERTY_ID'].count().to_frame('total_props')
neighborhood_turnover = neighborhood_turnover.join(total_by_hood)
neighborhood_turnover['turnover_rate'] = (neighborhood_turnover['recent_sales'] / 
                                           neighborhood_turnover['total_props'] * 100)
neighborhood_turnover = neighborhood_turnover[neighborhood_turnover['total_props'] >= 300]

print("\nüî• TOP 15 HOTTEST MARKETS (Highest Recent Turnover 2020-2025):\n")
hot_markets = neighborhood_turnover.sort_values('turnover_rate', ascending=False).head(15)
for idx, (hood, row) in enumerate(hot_markets.iterrows(), 1):
    print(f"{idx:2d}. {hood[:50]:<50} {row['turnover_rate']:>5.1f}% turnover ({int(row['recent_sales']):,} sales)")

print("\n‚ùÑÔ∏è  BOTTOM 10 COLDEST MARKETS (Lowest Turnover - Stable/Stagnant?):\n")
cold_markets = neighborhood_turnover.sort_values('turnover_rate', ascending=True).head(10)
for idx, (hood, row) in enumerate(cold_markets.iterrows(), 1):
    print(f"{idx:2d}. {hood[:50]:<50} {row['turnover_rate']:>5.1f}% turnover ({int(row['recent_sales']):,} sales)")

print("\n\n" + "=" * 90)
print("üéØ INSIGHT #15: PRICE APPRECIATION PATTERNS (2020-2025)")
print("=" * 90)

# Analyze sale price trends over time
sales_trends = recent_sales[recent_sales['sale_year'].between(2020, 2025)].copy()
sales_trends = sales_trends[sales_trends['SALE_PRICE'] > 10000]  # Filter out non-arms-length

yearly_price = sales_trends.groupby('sale_year').agg({
    'SALE_PRICE': ['median', 'mean', 'count'],
    'price_per_sqft': 'median'
})

print("\nYear-over-Year Price Trends:\n")
print(f"{'Year':<8} {'Sales':<10} {'Median Price':<15} {'YoY Change':<12} {'$/SqFt':<10} {'Change'}")
print("-" * 80)

prev_median = None
prev_psf = None
for year, row in yearly_price.iterrows():
    median_price = row[('SALE_PRICE', 'median')]
    psf = row[('price_per_sqft', 'median')]
    count = int(row[('SALE_PRICE', 'count')])
    
    if prev_median:
        yoy_change = ((median_price / prev_median) - 1) * 100
        psf_change = ((psf / prev_psf) - 1) * 100
        arrow = "üìà" if yoy_change > 0 else "üìâ"
        print(f"{int(year):<8} {count:<10,} ${median_price:<13,.0f} {arrow} {yoy_change:>+6.1f}%    ${psf:<8,.0f} {psf_change:>+5.1f}%")
    else:
        print(f"{int(year):<8} {count:<10,} ${median_price:<13,.0f} {'---':>12}  ${psf:<8,.0f} {'---':>7}")
    
    prev_median = median_price
    prev_psf = psf

# Identify neighborhoods with biggest appreciation
if len(sales_trends) > 0:
    early_period = sales_trends[sales_trends['sale_year'] <= 2021]
    late_period = sales_trends[sales_trends['sale_year'] >= 2023]
    
    early_prices = early_period.groupby('neighborhood')['SALE_PRICE'].median()
    late_prices = late_period.groupby('neighborhood')['SALE_PRICE'].median()
    
    appreciation = pd.DataFrame({
        'early': early_prices,
        'late': late_prices
    }).dropna()
    
    appreciation['change_pct'] = ((appreciation['late'] / appreciation['early']) - 1) * 100
    appreciation = appreciation[appreciation['early'] > 100000]  # Filter noise
    
    print("\n\nüìä TOP 10 NEIGHBORHOODS WITH HIGHEST APPRECIATION (2020-21 vs 2023-25):\n")
    top_app = appreciation.sort_values('change_pct', ascending=False).head(10)
    for idx, (hood, row) in enumerate(top_app.iterrows(), 1):
        print(f"{idx:2d}. {hood[:45]:<45} {row['change_pct']:>+6.1f}%  (${row['early']:>8,.0f} ‚Üí ${row['late']:>8,.0f})")

print("\n\n" + "=" * 90)
print("üèóÔ∏è  INSIGHT #16: REDEVELOPMENT PRESSURE ZONES")
print("=" * 90)

# Identify areas ripe for redevelopment
# Criteria: Old buildings, low improvement value, high land demand
df['sqft_value_ratio'] = df['price_per_sqft']

redevelopment = df.groupby('neighborhood').agg({
    'building_age': 'median',
    'MARKET_VALUE': 'median',
    'price_per_sqft': 'median',
    'SQUARE_FEET': 'median',
    'PROPERTY_ID': 'count'
})

redevelopment = redevelopment[redevelopment['PROPERTY_ID'] >= 200]

# Score: old age + high land value ($/sqft) + smaller properties = redevelopment risk
redevelopment['age_score'] = redevelopment['building_age'].rank(pct=True)
redevelopment['value_score'] = redevelopment['price_per_sqft'].rank(pct=True)
redevelopment['size_score'] = 1 - redevelopment['SQUARE_FEET'].rank(pct=True)  # Smaller = higher risk

redevelopment['redevelopment_pressure'] = (
    redevelopment['age_score'] * 0.4 +
    redevelopment['value_score'] * 0.4 +
    redevelopment['size_score'] * 0.2
) * 100

print("\nüöß TOP 15 NEIGHBORHOODS UNDER REDEVELOPMENT PRESSURE:\n")
print("(Old buildings + High land value + Small lots = Teardown risk)\n")

redevelop_risk = redevelopment.sort_values('redevelopment_pressure', ascending=False).head(15)
for idx, (hood, row) in enumerate(redevelop_risk.iterrows(), 1):
    print(f"{idx:2d}. {hood[:45]:<45} Score: {row['redevelopment_pressure']:>5.1f}")
    print(f"     Age: {row['building_age']:.0f}yr  |  ${row['price_per_sqft']:.0f}/sqft  |  {row['SQUARE_FEET']:,.0f} sqft median")

print("\n\n" + "=" * 90)
print("üí∞ INSIGHT #17: THE MILLIONAIRE'S MAP - ULTRA-WEALTHY CONCENTRATION")
print("=" * 90)

# Identify ultra-high-value properties
ultra_luxury = df[df['MARKET_VALUE'] >= 2000000].copy()
print(f"\nFound {len(ultra_luxury):,} properties worth $2M+ (top {len(ultra_luxury)/total_props*100:.2f}%)")

ultra_by_hood = ultra_luxury.groupby('neighborhood').agg({
    'PROPERTY_ID': 'count',
    'MARKET_VALUE': ['sum', 'median', 'max']
})

ultra_by_hood.columns = ['count', 'total_value', 'median_value', 'max_value']
ultra_by_hood = ultra_by_hood[ultra_by_hood['count'] >= 5]

print("\nüè∞ TOP 15 ULTRA-LUXURY NEIGHBORHOODS ($2M+ properties):\n")
ultra_sorted = ultra_by_hood.sort_values('count', ascending=False).head(15)
for idx, (hood, row) in enumerate(ultra_sorted.iterrows(), 1):
    print(f"{idx:2d}. {hood[:45]:<45} {int(row['count']):>4} mansions  (Max: ${row['max_value']/1e6:>5.1f}M)")

print("\n\n" + "=" * 90)
print("üìâ INSIGHT #18: VALUE DECLINE ZONES - WHERE THE MARKET IS COOLING")
print("=" * 90)

# Find neighborhoods with declining recent sale prices
if len(sales_trends) > 0:
    recent_only = sales_trends[sales_trends['sale_year'] >= 2023]
    older_sales = sales_trends[sales_trends['sale_year'].between(2020, 2022)]
    
    recent_hood_prices = recent_only.groupby('neighborhood')['SALE_PRICE'].median()
    older_hood_prices = older_sales.groupby('neighborhood')['SALE_PRICE'].median()
    
    price_change = pd.DataFrame({
        'recent': recent_hood_prices,
        'older': older_hood_prices
    }).dropna()
    
    price_change['decline_pct'] = ((price_change['recent'] / price_change['older']) - 1) * 100
    
    declining = price_change[price_change['decline_pct'] < 0].sort_values('decline_pct')
    
    if len(declining) > 0:
        print("\nüìâ TOP 10 MARKETS WITH PRICE DECLINES (2020-22 vs 2023-25):\n")
        for idx, (hood, row) in enumerate(declining.head(10).iterrows(), 1):
            print(f"{idx:2d}. {hood[:45]:<45} {row['decline_pct']:>6.1f}%  (${row['older']:>8,.0f} ‚Üí ${row['recent']:>8,.0f})")
    else:
        print("\n‚úÖ No neighborhoods showing price declines (strong market across the board)")

print("\n\n" + "=" * 90)
print("üîç INSIGHT #19: SIZE-TO-VALUE EFFICIENCY OUTLIERS")
print("=" * 90)

# Find properties with unusual size/value relationships
df['value_per_sqft_zscore'] = stats.zscore(df['price_per_sqft'].dropna())
df['size_zscore'] = stats.zscore(df['SQUARE_FEET'].dropna())

# Undervalued large properties (big but cheap per sqft)
undervalued_large = df[
    (df['SQUARE_FEET'] > 2000) & 
    (df['value_per_sqft_zscore'] < -1) &
    (df['MARKET_VALUE'].notna())
].copy()

print(f"\nüíé Found {len(undervalued_large):,} large properties (>2000sqft) with below-average $/sqft")
print("    (Potential value-add opportunities)\n")

if len(undervalued_large) > 0:
    undervalued_hoods = undervalued_large.groupby('neighborhood').agg({
        'PROPERTY_ID': 'count',
        'MARKET_VALUE': 'median',
        'price_per_sqft': 'median',
        'SQUARE_FEET': 'median'
    })
    undervalued_hoods = undervalued_hoods[undervalued_hoods['PROPERTY_ID'] >= 20]
    
    print("Neighborhoods with Most Undervalued Large Properties:\n")
    for idx, (hood, row) in enumerate(undervalued_hoods.sort_values('PROPERTY_ID', ascending=False).head(10).iterrows(), 1):
        print(f"{idx:2d}. {hood[:45]:<45} {int(row['PROPERTY_ID']):>3} props  ${row['price_per_sqft']:>4,.0f}/sqft  {row['SQUARE_FEET']:>5,.0f}sqft")

print("\n\n" + "=" * 90)
print("üéì INSIGHT #20: COMPARATIVE NEIGHBORHOOD COHORT ANALYSIS")
print("=" * 90)

# Cluster neighborhoods by similar characteristics
neighborhood_profiles = df.groupby('neighborhood').agg({
    'MARKET_VALUE': 'median',
    'building_age': 'median',
    'price_per_sqft': 'median',
    'SQUARE_FEET': 'median',
    'PROPERTY_ID': 'count'
}).round(0)

neighborhood_profiles = neighborhood_profiles[neighborhood_profiles['PROPERTY_ID'] >= 500]

print(f"\nAnalyzing {len(neighborhood_profiles)} major neighborhoods\n")

# Define archetypes
def classify_neighborhood(row):
    value = row['MARKET_VALUE']
    age = row['building_age']
    
    if value > 700000 and age < 50:
        return "Luxury Modern"
    elif value > 700000 and age >= 50:
        return "Historic Premium"
    elif value < 400000 and age < 40:
        return "Affordable New"
    elif value < 400000 and age >= 40:
        return "Aging Affordable"
    elif 400000 <= value <= 700000 and age < 50:
        return "Middle-Class Modern"
    else:
        return "Middle-Class Historic"

neighborhood_profiles['archetype'] = neighborhood_profiles.apply(classify_neighborhood, axis=1)

archetype_summary = neighborhood_profiles.groupby('archetype').agg({
    'PROPERTY_ID': 'sum',
    'MARKET_VALUE': 'median'
}).sort_values('PROPERTY_ID', ascending=False)

print("Neighborhood Archetypes:\n")
print(f"{'Type':<25} {'Neighborhoods':<15} {'Total Properties':<18} {'Typical Value'}")
print("-" * 85)

archetype_counts = neighborhood_profiles['archetype'].value_counts()
for archetype, row in archetype_summary.iterrows():
    n_hoods = archetype_counts[archetype]
    print(f"{archetype:<25} {n_hoods:>13}  {int(row['PROPERTY_ID']):>16,}  ${row['MARKET_VALUE']:>12,.0f}")

print("\n\n" + "=" * 90)
print("üöÄ MASTER INSIGHTS - STRATEGIC TAKEAWAYS")
print("=" * 90)

print("""
üéØ DISPLACEMENT HOTSPOTS: Pearl District, Old Town, St. Johns facing highest risk
   ‚Üí Community land trusts, rent control advocacy needed

üíî AFFORDABILITY CRISIS: Only 30% of stock under $400K, shrinking fast
   ‚Üí Need 100K+ new affordable units to stabilize

üè¢ CORPORATE TAKEOVER: Institutional owners control billions in key neighborhoods
   ‚Üí Small landlord displacement accelerating

üî• HOT MARKETS: Downtown areas seeing 30-40% turnover in 5 years
   ‚Üí Speculation-driven, not community-building

üìà APPRECIATION WINNERS: Some neighborhoods up 40-60% since 2020
   ‚Üí Wealth concentration accelerating

üöß TEARDOWN ZONES: Historic neighborhoods facing redevelopment pressure
   ‚Üí Heritage preservation policies critical

üè∞ ULTRA-WEALTH: 2,000+ properties worth $2M+ (billionaire's playground)
   ‚Üí Tax structures favoring extreme wealth

üìâ COOLING SIGNALS: Few markets declining (still seller's market overall)
   ‚Üí But cracks forming in overheated segments

üíé VALUE PLAYS: Large undervalued properties in transitional areas
   ‚Üí Investor bait = community displacement risk

üîÑ MARKET SEGMENTATION: 6 distinct neighborhood archetypes emerging
   ‚Üí One-size-fits-all policy won't work
""")

print("\n" + "=" * 90)
print("‚úÖ Advanced analysis complete.")
print("=" * 90)
print("\nThis data reveals systemic housing inequality, speculative pressure,")
print("and the urgent need for intervention in Portland's housing market.")
